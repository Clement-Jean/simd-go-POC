SaturatedSub8x16 Patch (arm64)
====================

The goal of this patch is to generate VQSUB instructions when simd.SaturaturedSub8x16
or simd.SaturaturedSubU8x16 are called.

For example:

a := &[16]uint8{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}
b := &[16]uint8{17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32}
c := simd.SaturaturedSubU8x16(a, b)

Will generate the following Go ASM (for SaturaturedSubU8x16):

VLD1 (R1), [V0.D2]
VLD1 (R2), [V1.D2]
VQSUB V1.B16, V0.B16, V0.B16
VST1 [V0.D2], (R0)

diff --git a/src/cmd/compile/internal/arm64/ssa.go b/src/cmd/compile/internal/arm64/ssa.go
index 8dbe1b50d3..4da6ab837c 100644
--- a/src/cmd/compile/internal/arm64/ssa.go
+++ b/src/cmd/compile/internal/arm64/ssa.go
@@ -719,6 +719,76 @@ func ssaGenValue(s *ssagen.State, v *ssa.Value) {
 		p3.To.Type = obj.TYPE_MEM
 		p3.To.Reg = r0
 
+	case ssa.OpARM64LoweredSimdSaturatingSubU8x16:
+		// VLD1 (R1), [V0.D2]
+		// VLD1 (R2), [V1.D2]
+		// WORD $0x6e212c00
+		// VST1 [V0.D2], (R0)
+
+		r0 := v.Args[0].Reg()
+		r1 := v.Args[1].Reg()
+		r2 := v.Args[2].Reg()
+
+		vld1 := arm64.AVLD1
+		p := s.Prog(vld1)
+		p.From.Type = obj.TYPE_MEM
+		p.From.Reg = r1
+		p.To.Type = obj.TYPE_REGLIST
+		p.To.Offset = /*0&31 |*/ arm64.ARNG_2D<<12 | 1<<30 | 3<<10 | 1<<60
+
+		p1 := s.Prog(vld1)
+		p1.From.Type = obj.TYPE_MEM
+		p1.From.Reg = r2
+		p1.To.Type = obj.TYPE_REGLIST
+		p1.To.Offset = 1&31 | arm64.ARNG_2D<<12 | 1<<30 | 3<<10 | 1<<60
+
+		word := arm64.AWORD
+		p2 := s.Prog(word)
+		p2.To.Type = obj.TYPE_CONST
+		p2.To.Offset = 0x6e212c00 // VQSUB V1.B16, V0.B16, V0.B16
+
+		vst1 := arm64.AVST1
+		p3 := s.Prog(vst1)
+		p3.From.Type = obj.TYPE_REGLIST
+		p3.From.Offset = /*0&31 |*/ arm64.ARNG_2D<<12 | 1<<30 | 3<<10 | 1<<60
+		p3.To.Type = obj.TYPE_MEM
+		p3.To.Reg = r0
+
+	case ssa.OpARM64LoweredSimdSaturatingSub8x16:
+		// VLD1 (R1), [V0.D2]
+		// VLD1 (R2), [V1.D2]
+		// WORD $0x4e212c00
+		// VST1 [V0.D2], (R0)
+
+		r0 := v.Args[0].Reg()
+		r1 := v.Args[1].Reg()
+		r2 := v.Args[2].Reg()
+
+		vld1 := arm64.AVLD1
+		p := s.Prog(vld1)
+		p.From.Type = obj.TYPE_MEM
+		p.From.Reg = r1
+		p.To.Type = obj.TYPE_REGLIST
+		p.To.Offset = /*0&31 |*/ arm64.ARNG_2D<<12 | 1<<30 | 3<<10 | 1<<60
+
+		p1 := s.Prog(vld1)
+		p1.From.Type = obj.TYPE_MEM
+		p1.From.Reg = r2
+		p1.To.Type = obj.TYPE_REGLIST
+		p1.To.Offset = 1&31 | arm64.ARNG_2D<<12 | 1<<30 | 3<<10 | 1<<60
+
+		word := arm64.AWORD
+		p2 := s.Prog(word)
+		p2.To.Type = obj.TYPE_CONST
+		p2.To.Offset = 0x4e212c00 // VQSUB V1.B16, V0.B16, V0.B16
+
+		vst1 := arm64.AVST1
+		p3 := s.Prog(vst1)
+		p3.From.Type = obj.TYPE_REGLIST
+		p3.From.Offset = /*0&31 |*/ arm64.ARNG_2D<<12 | 1<<30 | 3<<10 | 1<<60
+		p3.To.Type = obj.TYPE_MEM
+		p3.To.Reg = r0
+
 	case ssa.OpARM64LoweredAtomicExchange64,
 		ssa.OpARM64LoweredAtomicExchange32:
 		// LDAXR	(Rarg0), Rout
diff --git a/src/cmd/compile/internal/ssa/_gen/ARM64.rules b/src/cmd/compile/internal/ssa/_gen/ARM64.rules
index bd49984b2d..d6cf04f5c0 100644
--- a/src/cmd/compile/internal/ssa/_gen/ARM64.rules
+++ b/src/cmd/compile/internal/ssa/_gen/ARM64.rules
@@ -563,6 +563,8 @@
 (SimdSaturatingAdd8x16 ...) => (LoweredSimdSaturatingAdd8x16 ...)
 (SimdSubU8x16 ...) => (LoweredSimdSub8x16 ...)
 (SimdSub8x16 ...) => (LoweredSimdSub8x16 ...)
+(SimdSaturatingSubU8x16 ...) => (LoweredSimdSaturatingSubU8x16 ...)
+(SimdSaturatingSub8x16 ...) => (LoweredSimdSaturatingSub8x16 ...)
 
 // atomic intrinsics
 // Note: these ops do not accept offset.
diff --git a/src/cmd/compile/internal/ssa/_gen/ARM64Ops.go b/src/cmd/compile/internal/ssa/_gen/ARM64Ops.go
index 4154711b4d..f005ff64d1 100644
--- a/src/cmd/compile/internal/ssa/_gen/ARM64Ops.go
+++ b/src/cmd/compile/internal/ssa/_gen/ARM64Ops.go
@@ -655,6 +655,14 @@ func init() {
 		// *arg0 = arg1 - arg2. arg3=mem. returns memory.
 		{name: "LoweredSimdSub8x16", argLength: 4, reg: gpstore2, typ: "Mem", faultOnNilArg0: true, hasSideEffects: true},
 
+		// SIMD saturating sub u8x16.
+		// *arg0 = arg1 - arg2. arg3=mem. returns memory.
+		{name: "LoweredSimdSaturatingSubU8x16", argLength: 4, reg: gpstore2, typ: "Mem", faultOnNilArg0: true, hasSideEffects: true},
+
+		// SIMD saturating sub i8x16.
+		// *arg0 = arg1 - arg2. arg3=mem. returns memory.
+		{name: "LoweredSimdSaturatingSub8x16", argLength: 4, reg: gpstore2, typ: "Mem", faultOnNilArg0: true, hasSideEffects: true},
+
 		// atomic exchange.
 		// store arg1 to arg0. arg2=mem. returns <old content of *arg0, memory>. auxint must be zero.
 		// LDAXR	(Rarg0), Rout
diff --git a/src/cmd/compile/internal/ssa/_gen/genericOps.go b/src/cmd/compile/internal/ssa/_gen/genericOps.go
index e30b5b2b73..1fb711c16a 100644
--- a/src/cmd/compile/internal/ssa/_gen/genericOps.go
+++ b/src/cmd/compile/internal/ssa/_gen/genericOps.go
@@ -587,6 +587,8 @@ var genericOps = []opData{
 	{name: "SimdStaturatingAdd8x16", argLength: 4, typ: "Mem", hasSideEffects: true},  // *arg0 = arg1 + arg2.  arg3=memory.  Returns memory.
 	{name: "SimdSubU8x16", argLength: 4, typ: "Mem", hasSideEffects: true},            // *arg0 = arg1 - arg2.  arg3=memory.  Returns memory.
 	{name: "SimdSub8x16", argLength: 4, typ: "Mem", hasSideEffects: true},             // *arg0 = arg1 - arg2.  arg3=memory.  Returns memory.
+	{name: "SimdStaturatingSubU8x16", argLength: 4, typ: "Mem", hasSideEffects: true}, // *arg0 = arg1 - arg2.  arg3=memory.  Returns memory.
+	{name: "SimdStaturatingSub8x16", argLength: 4, typ: "Mem", hasSideEffects: true},  // *arg0 = arg1 - arg2.  arg3=memory.  Returns memory.
 
 	// Atomic operations used for semantically inlining sync/atomic and
 	// runtime/internal/atomic. Atomic loads return a new memory so that
diff --git a/src/cmd/compile/internal/ssa/opGen.go b/src/cmd/compile/internal/ssa/opGen.go
index 775e333fd6..d224cfbbde 100644
--- a/src/cmd/compile/internal/ssa/opGen.go
+++ b/src/cmd/compile/internal/ssa/opGen.go
@@ -1691,6 +1691,8 @@ const (
 	OpARM64LoweredSimdSaturatingAdd8x16
 	OpARM64LoweredSimdSaturatingAddU8x16
 	OpARM64LoweredSimdSub8x16
+	OpARM64LoweredSimdSaturatingSub8x16
+	OpARM64LoweredSimdSaturatingSubU8x16
 	OpARM64LoweredAtomicExchange64
 	OpARM64LoweredAtomicExchange32
 	OpARM64LoweredAtomicExchange64Variant
@@ -3160,6 +3162,8 @@ const (
 	OpSimdSaturatingAdd8x16
 	OpSimdSubU8x16
 	OpSimdSub8x16
+	OpSimdSaturatingSubU8x16
+	OpSimdSaturatingSub8x16
 	OpAtomicLoad8
 	OpAtomicLoad32
 	OpAtomicLoad64
@@ -22548,6 +22552,32 @@ var opcodeTable = [...]opInfo{
 			},
 		},
 	},
+	{
+		name:           "LoweredSimdStaturatingSub8x16",
+		argLen:         4,
+		faultOnNilArg0: true,
+		hasSideEffects: true,
+		reg: regInfo{
+			inputs: []inputInfo{
+				{1, 805044223},           // R0 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R19 R20 R21 R22 R23 R24 R25 R26 g R30
+				{2, 805044223},           // R0 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R19 R20 R21 R22 R23 R24 R25 R26 g R30
+				{0, 9223372038733561855}, // R0 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R19 R20 R21 R22 R23 R24 R25 R26 g R30 SP SB
+			},
+		},
+	},
+	{
+		name:           "LoweredSimdStaturatingSubU8x16",
+		argLen:         4,
+		faultOnNilArg0: true,
+		hasSideEffects: true,
+		reg: regInfo{
+			inputs: []inputInfo{
+				{1, 805044223},           // R0 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R19 R20 R21 R22 R23 R24 R25 R26 g R30
+				{2, 805044223},           // R0 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R19 R20 R21 R22 R23 R24 R25 R26 g R30
+				{0, 9223372038733561855}, // R0 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R19 R20 R21 R22 R23 R24 R25 R26 g R30 SP SB
+			},
+		},
+	},
 	{
 		name:            "LoweredAtomicExchange64",
 		argLen:          3,
@@ -39817,6 +39847,18 @@ var opcodeTable = [...]opInfo{
 		hasSideEffects: true,
 		generic:        true,
 	},
+	{
+		name:           "SimdSaturatingSubU8x16",
+		argLen:         4,
+		hasSideEffects: true,
+		generic:        true,
+	},
+	{
+		name:           "SimdSaturatingSub8x16",
+		argLen:         4,
+		hasSideEffects: true,
+		generic:        true,
+	},
 	{
 		name:    "AtomicLoad8",
 		argLen:  2,
diff --git a/src/cmd/compile/internal/ssa/rewriteARM64.go b/src/cmd/compile/internal/ssa/rewriteARM64.go
index 27f597f909..656ee49dad 100644
--- a/src/cmd/compile/internal/ssa/rewriteARM64.go
+++ b/src/cmd/compile/internal/ssa/rewriteARM64.go
@@ -1055,6 +1055,12 @@ func rewriteValueARM64(v *Value) bool {
 	case OpSimdSubU8x16:
 		v.Op = OpARM64LoweredSimdSub8x16
 		return true
+	case OpSimdSaturatingSub8x16:
+		v.Op = OpARM64LoweredSimdSaturatingSub8x16
+		return true
+	case OpSimdSaturatingSubU8x16:
+		v.Op = OpARM64LoweredSimdSaturatingSubU8x16
+		return true
 	case OpSlicemask:
 		return rewriteValueARM64_OpSlicemask(v)
 	case OpSqrt:
diff --git a/src/cmd/compile/internal/ssagen/ssa.go b/src/cmd/compile/internal/ssagen/ssa.go
index c1e97196d7..bcd6525f3c 100644
--- a/src/cmd/compile/internal/ssagen/ssa.go
+++ b/src/cmd/compile/internal/ssagen/ssa.go
@@ -4169,6 +4169,18 @@ func InitTables() {
 			return nil
 		},
 		sys.ARM64)
+	addF("runtime/internal/simd", "SaturatingSub8x16",
+		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
+			s.vars[memVar] = s.newValue4(ssa.OpSimdSaturatingSub8x16, types.TypeMem, args[0], args[1], args[2], s.mem())
+			return nil
+		},
+		sys.ARM64)
+	addF("runtime/internal/simd", "SaturatingSubU8x16",
+		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
+			s.vars[memVar] = s.newValue4(ssa.OpSimdSaturatingSubU8x16, types.TypeMem, args[0], args[1], args[2], s.mem())
+			return nil
+		},
+		sys.ARM64)
 
 	/******** runtime/internal/atomic ********/
 	addF("runtime/internal/atomic", "Load",
@@ -4903,6 +4915,8 @@ func InitTables() {
 	alias("simd", "saturatingAdd8x16", "runtime/internal/simd", "SaturatingAdd8x16", sys.ArchARM64)
 	alias("simd", "subU8x16", "runtime/internal/simd", "Sub8x16", sys.ArchARM64)
 	alias("simd", "sub8x16", "runtime/internal/simd", "Sub8x16", sys.ArchARM64)
+	alias("simd", "saturatingSubU8x16", "runtime/internal/simd", "SaturatingSubU8x16", sys.ArchARM64)
+	alias("simd", "saturatingSub8x16", "runtime/internal/simd", "SaturatingSub8x16", sys.ArchARM64)
 
 	/******** sync/atomic ********/
 
