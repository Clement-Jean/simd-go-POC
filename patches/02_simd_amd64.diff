diff --git a/src/cmd/compile/internal/amd64/ssa.go b/src/cmd/compile/internal/amd64/ssa.go
index ab762c24f6..ff73cb78f8 100644
--- a/src/cmd/compile/internal/amd64/ssa.go
+++ b/src/cmd/compile/internal/amd64/ssa.go
@@ -1250,6 +1250,46 @@ func ssaGenValue(s *ssagen.State, v *ssa.Value) {
 		if base.Debug.Nil != 0 && v.Pos.Line() > 1 { // v.Pos.Line()==1 in generated wrappers
 			base.WarnfAt(v.Pos, "generated nil check")
 		}
+
+	case ssa.OpAMD64LoweredSimdAdd8x16:
+		// VMOVDQA (arg1), X0
+		// VMOVDQA (arg2), X1
+		// VPADDB X1, X0, X0
+		// VMOVDQA X0, (arg0)
+
+		r0 := v.Args[0].Reg()
+		r1 := v.Args[1].Reg()
+		r2 := v.Args[2].Reg()
+
+		vmovdqa := x86.AVMOVDQA
+		p := s.Prog(vmovdqa)
+		p.From.Type = obj.TYPE_MEM
+		p.From.Reg = r1
+		p.To.Type = obj.TYPE_REG
+		p.To.Reg = x86.REG_X0
+
+		p1 := s.Prog(vmovdqa)
+		p1.From.Type = obj.TYPE_MEM
+		p1.From.Reg = r2
+		p1.To.Type = obj.TYPE_REG
+		p1.To.Reg = x86.REG_X1
+
+		vpaddb := x86.AVPADDB
+		p2 := s.Prog(vpaddb)
+		p2.From.Type = obj.TYPE_REG
+		p2.From.Reg = x86.REG_X0
+		p2.RestArgs = []obj.AddrPos{
+			{Addr: obj.Addr{Type: obj.TYPE_REG, Reg: x86.REG_X1}},
+		}
+		p2.To.Type = obj.TYPE_REG
+		p2.To.Reg = x86.REG_X0
+
+		p3 := s.Prog(vmovdqa)
+		p3.From.Type = obj.TYPE_REG
+		p3.From.Reg = x86.REG_X0
+		p3.To.Type = obj.TYPE_MEM
+		p3.To.Reg = r0
+
 	case ssa.OpAMD64MOVBatomicload, ssa.OpAMD64MOVLatomicload, ssa.OpAMD64MOVQatomicload:
 		p := s.Prog(v.Op.Asm())
 		p.From.Type = obj.TYPE_MEM
diff --git a/src/cmd/compile/internal/ssa/_gen/AMD64.rules b/src/cmd/compile/internal/ssa/_gen/AMD64.rules
index 2a4c59ebfc..2a71b740ac 100644
--- a/src/cmd/compile/internal/ssa/_gen/AMD64.rules
+++ b/src/cmd/compile/internal/ssa/_gen/AMD64.rules
@@ -549,6 +549,10 @@
 
 (JumpTable idx) => (JUMPTABLE {makeJumpTableSym(b)} idx (LEAQ <typ.Uintptr> {makeJumpTableSym(b)} (SB)))
 
+// simd intrinsics
+(SimdAddU8x16 ...) => (LoweredSimdAdd8x16 ...)
+(SimdAdd8x16 ...) => (LoweredSimdAdd8x16 ...)
+
 // Atomic loads.  Other than preserving their ordering with respect to other loads, nothing special here.
 (AtomicLoad8 ptr mem) => (MOVBatomicload ptr mem)
 (AtomicLoad32 ptr mem) => (MOVLatomicload ptr mem)
diff --git a/src/cmd/compile/internal/ssa/_gen/AMD64Ops.go b/src/cmd/compile/internal/ssa/_gen/AMD64Ops.go
index 606171947b..d07b704dd4 100644
--- a/src/cmd/compile/internal/ssa/_gen/AMD64Ops.go
+++ b/src/cmd/compile/internal/ssa/_gen/AMD64Ops.go
@@ -981,6 +981,10 @@ func init() {
 		{name: "LoweredPanicBoundsB", argLength: 3, aux: "Int64", reg: regInfo{inputs: []regMask{cx, dx}}, typ: "Mem", call: true}, // arg0=idx, arg1=len, arg2=mem, returns memory. AuxInt contains report code (see PanicBounds in generic.go).
 		{name: "LoweredPanicBoundsC", argLength: 3, aux: "Int64", reg: regInfo{inputs: []regMask{ax, cx}}, typ: "Mem", call: true}, // arg0=idx, arg1=len, arg2=mem, returns memory. AuxInt contains report code (see PanicBounds in generic.go).
 
+		// SIMD wrapping add u8x16.
+		// *arg0 = arg1 + arg2. arg3=mem. returns memory.
+		{name: "LoweredSimdAdd8x16", argLength: 4, reg: regInfo{inputs: []regMask{gpsp}}, typ: "Mem", faultOnNilArg0: true, hasSideEffects: true},
+
 		// Constant flag values. For any comparison, there are 5 possible
 		// outcomes: the three from the signed total order (<,==,>) and the
 		// three from the unsigned total order. The == cases overlap.
diff --git a/src/cmd/compile/internal/ssa/opGen.go b/src/cmd/compile/internal/ssa/opGen.go
index 88326aa8b4..350e9d502e 100644
--- a/src/cmd/compile/internal/ssa/opGen.go
+++ b/src/cmd/compile/internal/ssa/opGen.go
@@ -1052,6 +1052,7 @@ const (
 	OpAMD64LoweredPanicBoundsA
 	OpAMD64LoweredPanicBoundsB
 	OpAMD64LoweredPanicBoundsC
+	OpAMD64LoweredSimdAdd8x16
 	OpAMD64FlagEQ
 	OpAMD64FlagLT_ULT
 	OpAMD64FlagLT_UGT
@@ -13882,6 +13883,17 @@ var opcodeTable = [...]opInfo{
 			},
 		},
 	},
+	{
+		name:           "LoweredSimdAdd8x16",
+		argLen:         4,
+		faultOnNilArg0: true,
+		hasSideEffects: true,
+		reg: regInfo{
+			inputs: []inputInfo{
+				{0, 49151}, // AX CX DX BX SP BP SI DI R8 R9 R10 R11 R12 R13 R15
+			},
+		},
+	},
 	{
 		name:   "FlagEQ",
 		argLen: 0,
diff --git a/src/cmd/compile/internal/ssa/rewriteAMD64.go b/src/cmd/compile/internal/ssa/rewriteAMD64.go
index ba71189703..697cf98694 100644
--- a/src/cmd/compile/internal/ssa/rewriteAMD64.go
+++ b/src/cmd/compile/internal/ssa/rewriteAMD64.go
@@ -1092,6 +1092,12 @@ func rewriteValueAMD64(v *Value) bool {
 	case OpSignExt8to64:
 		v.Op = OpAMD64MOVBQSX
 		return true
+	case OpSimdAdd8x16:
+		v.Op = OpAMD64LoweredSimdAdd8x16
+		return true
+	case OpSimdAddU8x16:
+		v.Op = OpAMD64LoweredSimdAdd8x16
+		return true
 	case OpSlicemask:
 		return rewriteValueAMD64_OpSlicemask(v)
 	case OpSpectreIndex:
diff --git a/src/cmd/compile/internal/ssagen/ssa.go b/src/cmd/compile/internal/ssagen/ssa.go
index 760a7f8d06..3f758e07d4 100644
--- a/src/cmd/compile/internal/ssagen/ssa.go
+++ b/src/cmd/compile/internal/ssagen/ssa.go
@@ -4293,7 +4293,7 @@ func InitTables() {
 			s.vars[memVar] = s.newValue4(ssa.OpSimdAdd8x16, types.TypeMem, args[0], args[1], args[2], s.mem())
 			return nil
 		},
-		sys.ARM64)
+		sys.AMD64, sys.ARM64)
 	addF("runtime/internal/simd", "SaturatingAdd8x16",
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
 			s.vars[memVar] = s.newValue4(ssa.OpSimdSaturatingAdd8x16, types.TypeMem, args[0], args[1], args[2], s.mem())
@@ -5123,8 +5123,8 @@ func InitTables() {
 	alias("runtime/internal/sys", "OnesCount64", "math/bits", "OnesCount64", all...)
 
 	/******** simd ********/
-	alias("simd", "addU8x16", "runtime/internal/simd", "Add8x16", sys.ArchARM64)
-	alias("simd", "add8x16", "runtime/internal/simd", "Add8x16", sys.ArchARM64)
+	alias("simd", "addU8x16", "runtime/internal/simd", "Add8x16", sys.ArchARM64, sys.ArchAMD64)
+	alias("simd", "add8x16", "runtime/internal/simd", "Add8x16", sys.ArchARM64, sys.ArchAMD64)
 	alias("simd", "saturatingAddU8x16", "runtime/internal/simd", "SaturatingAddU8x16", sys.ArchARM64)
 	alias("simd", "saturatingAdd8x16", "runtime/internal/simd", "SaturatingAdd8x16", sys.ArchARM64)
 	alias("simd", "subU8x16", "runtime/internal/simd", "Sub8x16", sys.ArchARM64)
